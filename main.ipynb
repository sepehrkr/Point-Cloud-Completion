{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":4651,"status":"ok","timestamp":1693771819259,"user":{"displayName":"sepehr kazemi","userId":"16765035425808681494"},"user_tz":-210},"id":"Fwvcd2zu7r67"},"outputs":[],"source":["import torch\n","from torch import Tensor\n","import torch.nn.functional as F\n","from torch import nn\n","from tqdm import tqdm\n","from torch.utils.data import DataLoader, Dataset\n","from torchvision import transforms\n","import numpy as np\n","from PIL import Image\n","from torch_cluster import knn_graph, fps\n","from math import sqrt\n","import matplotlib.pyplot as plt\n","import h5py\n","from torch_cluster import fps\n","from torch_cluster import knn\n","from datetime import datetime\n","from torch_geometric.datasets import ShapeNet\n","from collections import Counter"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":500,"status":"ok","timestamp":1693768718771,"user":{"displayName":"sepehr kazemi","userId":"16765035425808681494"},"user_tz":-210},"id":"u2OaJXuJ7r68"},"outputs":[],"source":["def distance(index, point_cloud):\n","        return torch.norm(point_cloud[index]-point_cloud,dim=-1)\n","\n","def fps_complete(point_cloud, unique_indexes, M):\n","    t = len(unique_indexes)\n","    if t >= M :\n","        return unique_indexes\n","\n","    fps_indexes = torch.zeros(M)\n","    fps_indexes[0:t] = unique_indexes\n","    minimum_distance = distance(fps_indexes[0], point_cloud)\n","    for i in range(1,t):\n","        minimum_distance = torch.minimum(minimum_distance, distance(fps_indexes[i], point_cloud))\n","\n","    for i in range(t,M):\n","        fps_indexes[i] = minimum_distance.argmax()\n","        minimum_distance = torch.minimum(minimum_distance, distance(fps_indexes[i], point_cloud))\n","    return fps_indexes\n","\n","class SmapleNet(nn.Module):\n","    def __init__(self, input_points, output_points, k, bottleneck, device, initial_temperature=1.0, is_temperature_trainable=True, skip_projection=False):\n","        super().__init__()\n","\n","        self.input_points = input_points\n","        self.output_points = output_points\n","        self.k = k\n","        self.device = device\n","        self.training = True\n","        self.skip_projection = skip_projection\n","        self.temperature = torch.nn.Parameter(\n","            torch.tensor(\n","                initial_temperature,\n","                requires_grad=is_temperature_trainable,\n","                dtype=torch.float32,\n","            ))\n","\n","        self.conv1 = nn.Sequential(nn.Conv1d(3,64,1), nn.BatchNorm1d(64), nn.PReLU())\n","        self.conv2 = nn.Sequential(nn.Conv1d(64,64,1), nn.BatchNorm1d(64), nn.PReLU())\n","        self.conv3 = nn.Sequential(nn.Conv1d(64,64,1), nn.BatchNorm1d(64), nn.PReLU())\n","        self.conv4 = nn.Sequential(nn.Conv1d(64,128,1), nn.BatchNorm1d(128), nn.PReLU())\n","        self.conv5 = nn.Sequential(nn.Conv1d(128,bottleneck,1), nn.BatchNorm1d(bottleneck), nn.PReLU())\n","\n","        self.fc1 = nn.Sequential(nn.Linear(bottleneck,256), nn.BatchNorm1d(256), nn.PReLU())\n","        self.fc2 = nn.Sequential(nn.Linear(256,256), nn.BatchNorm1d(256), nn.PReLU())\n","        self.fc3 = nn.Sequential(nn.Linear(256,256), nn.BatchNorm1d(256), nn.PReLU())\n","        self.fc4 = nn.Sequential(nn.Linear(256,3*output_points))\n","\n","        self.softmax = nn.Softmax(dim=-1)\n","\n","    def forward(self, x):\n","        # x must has shape B x N x C\n","        x = torch.swapaxes(x,1,2)\n","        y = self.conv1(x)\n","        y = self.conv2(y)\n","        y = self.conv3(y)\n","        y = self.conv4(y)\n","        y = self.conv5(y)\n","        y = y.max(dim=2)[0]\n","        y = self.fc1(y)\n","        y = self.fc2(y)\n","        y = self.fc3(y)\n","        y = self.fc4(y)\n","        y = y.reshape((-1,3,self.output_points)).swapaxes(1,2)\n","\n","        if self.training:\n","            if not self.skip_projection:\n","                return self.softProjection(x.swapaxes(1,2),y,self.k)\n","            else:\n","                return y\n","        else:\n","            return self.matching(x.swapaxes(1,2),y,self.k)\n","\n","    def softProjection(self,point_cloud, query_cloud, k):\n","        # point cloud and query cloud has shape B x N x C\n","        B, N, _ = point_cloud.shape\n","        B, M, _ = query_cloud.shape\n","        point_cloud = point_cloud.reshape((B*N,-1))\n","        query_cloud = query_cloud.reshape((B*M,-1))\n","        batch_x = torch.repeat_interleave(torch.arange(B),N).to(self.device)\n","        batch_y = torch.repeat_interleave(torch.arange(B),M).to(self.device)\n","        dist = knn(point_cloud, query_cloud, k, batch_x, batch_y)\n","\n","        exponent = -torch.norm(point_cloud[dist[1]]-query_cloud[dist[0]],dim=-1).reshape(B,M,k) / (self.temperature ** 2)\n","        weights = self.softmax(exponent)\n","        projected_points = torch.sum(point_cloud[dist[1]].reshape(B,M,k,-1) * weights[:,:,:,None],dim=2)\n","        return projected_points\n","\n","    def matching(self, point_cloud, query_cloud):\n","        # point cloud and query cloud has shape B x N x C\n","        B, N, _ = point_cloud.shape\n","        B, M, _ = query_cloud.shape\n","        point_cloud = point_cloud.reshape((B*N,-1))\n","        query_cloud = query_cloud.reshape((B*M,-1))\n","        batch_x = torch.repeat_interleave(torch.arange(B),N).to(self.device)\n","        batch_y = torch.repeat_interleave(torch.arange(B),M).to(self.device)\n","        dist = knn(point_cloud, query_cloud, 1, batch_x, batch_y)\n","        indexes = dist[1].reshape((B,M))\n","        sampled_points = torch.zeros((B,M), device=self.device)\n","        for b in range(B):\n","            unique_indexes = indexes[b].unique()\n","            sampled_points[b,:] = fps_complete(point_cloud[b],unique_indexes,M)\n","\n","        return point_cloud[sampled_points.flatten()].reshape(B,M,-1)\n","\n"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1693771859841,"user":{"displayName":"sepehr kazemi","userId":"16765035425808681494"},"user_tz":-210},"id":"qZxoWRS87r6-"},"outputs":[],"source":["def display_pointClouds(pc1:torch.Tensor, pc2:torch.Tensor):\n","    # pc1, pc2 has shape B x N x 3\n","    B, _, _ = pc1.shape\n","    fig = plt.figure(figsize=(8,120))\n","    for i in range(0,B):\n","        ax = fig.add_subplot(B,2,2*i+1,projection='3d')\n","        ax.scatter(pc1[i,:,0],pc1[i,:,1],pc1[i,:,2])\n","        ax = fig.add_subplot(B,2,2*i+2,projection='3d')\n","        ax.scatter(pc2[i,:,0],pc2[i,:,1],pc2[i,:,2])\n","    plt.show()"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1693771861581,"user":{"displayName":"sepehr kazemi","userId":"16765035425808681494"},"user_tz":-210},"id":"6kC3d4pj7r6-"},"outputs":[],"source":["class MVPDataset(Dataset):\n","    def __init__(self,path):\n","        super(MVPDataset,self).__init__()\n","\n","        self.file = h5py.File(path,'r')\n","        self.keys = list(self.file.keys())\n","        self.count = 26\n","\n","    def __getitem__(self, index):\n","        partial_pc = torch.tensor(self.file[self.keys[1]][index][()])\n","        complete_pc = torch.tensor(self.file[self.keys[0]][index//self.count][()])\n","        N, D = partial_pc.shape\n","        indexes = (fps(partial_pc,ratio=0.25)%N)\n","        sampled_partial = partial_pc[indexes]\n","        return sampled_partial, complete_pc\n","\n","    def __len__(self):\n","        return len(self.file[self.keys[1]][()])"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":14728,"status":"ok","timestamp":1693771883087,"user":{"displayName":"sepehr kazemi","userId":"16765035425808681494"},"user_tz":-210},"id":"J6oDWmez7r6_"},"outputs":[],"source":["batch_size = 32\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","trainset = MVPDataset('./MVP_Train_CP.h5')\n","testset = MVPDataset('./MVP_Test_CP.h5')\n","\n","trainLoader = DataLoader(trainset,batch_size,shuffle=True)\n","testLoader = DataLoader(testset,batch_size,shuffle=True)"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["queries = torch.rand(32,512,3)\n","keys = values = queries\n","atten = nn.MultiheadAttention(3,3,batch_first=True)\n","y = atten(queries,keys,values)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class multiHeadAttension(nn.Module):\n","    def __init__(self,in_channel, out_channel):\n","        super(multiHeadAttension,self).__init__()\n","        self.linq = "]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":522,"status":"ok","timestamp":1693771888085,"user":{"displayName":"sepehr kazemi","userId":"16765035425808681494"},"user_tz":-210},"id":"kEfAJcB47r6_"},"outputs":[],"source":["class SRGCN(nn.Module):\n","    def __init__(self, optype:str, in_channel, out_channel, device, k=9, dilation=1, stride=1):\n","        super().__init__()\n","        assert optype in {'conv','max','avg'}\n","        self.optype = optype\n","        self.dilation = dilation\n","        self.k = k\n","        self.stride = stride\n","        self.in_channel = in_channel\n","        self.out_channel = out_channel\n","        self.device = device\n","\n","        self.attention = nn.MultiheadAttention()\n","        self.mlp = nn.Sequential(nn.Linear(2*in_channel,out_channel), nn.LeakyReLU(inplace=True), nn.Linear(out_channel,out_channel))\n","\n","    def forward(self, x:torch.Tensor):\n","        # path has shape B x M\n","        path = self.traverse_graph(x)\n","        B, N, D = x.shape\n","        _, M = path.shape\n","        batches = torch.arange(B)[:,None]\n","\n","        batch_tensor = torch.repeat_interleave(torch.arange(B),N).to(self.device)\n","        if self.dilation == 1:\n","            indexes = (knn_graph(x.reshape(B*N,-1),self.k,batch_tensor)%N)[0].reshape((B,N,-1))[batches,path]\n","        else:\n","            indexes = (knn_graph(x.reshape(B*N,-1),self.k * self.dilation,batch_tensor)%N)[0].reshape((B,N,-1))[batches,path][:,:,torch.arange(0,self.k*self.dilation,self.dilation)]\n","\n","        message = x[batches,indexes.reshape((B,-1))].reshape((B,M,self.k,-1))\n","        if self.optype == 'conv':\n","            \n","            \n","            #aggr = (message - x[batches,path][:,:,None,:]).max(dim=-2)[0]\n","            #mlp_prep = torch.cat((x[batches,path],aggr),dim=-1).reshape((B*M,-1))\n","            #return self.mlp(mlp_prep).reshape(B,M,-1)\n","        elif self.optype == 'max':\n","            return torch.cat((x[batches,path][:,:,None,:],message),dim=-2).max(dim=-2)[0]\n","        else:\n","            return torch.cat((x[batches,path][:,:,None,:],message),dim=-2).mean(dim=-2)\n","\n","    def traverse_graph(self, x:torch.Tensor):\n","        # x has shape B x N x D\n","        x = x.clone().detach()\n","        B, N, D = x.shape\n","        if self.stride > 1:\n","            current_vertex = torch.randint(N,size=(B,1)).to(device)\n","            path_length = 1\n","            path = [current_vertex.squeeze()]\n","            batches = torch.arange(B)[:,None].to(device)\n","            #batch_tensor = torch.repeat_interleave(torch.arange(B),N)\n","            while(path_length<N//self.stride):\n","                _, indexes = torch.topk(torch.norm(x[batches,current_vertex]-x,dim=-1),k=self.stride+1,largest=False)\n","                x[batches,indexes[:,0:self.stride]] = torch.inf\n","                current_vertex = indexes[batches,[-1]]\n","                path.append(current_vertex.squeeze())\n","                path_length += 1\n","            return torch.stack(path).swapaxes(1,0)\n","        else:\n","            return torch.arange(N).to(device).repeat(B,1)"]},{"cell_type":"code","execution_count":37,"metadata":{},"outputs":[],"source":["x = torch.rand(32,256,64)\n","device = torch.device('cpu')\n","conv = SRGCN('conv',64,64,device,dilation=8)\n","y = conv(x)"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1693771895761,"user":{"displayName":"sepehr kazemi","userId":"16765035425808681494"},"user_tz":-210},"id":"lL5jJH7t7r6_"},"outputs":[],"source":["class Upsampling(nn.Module):\n","    def __init__(self, in_channel:int, device, factor:int=2, k:int=9, D:int=4):\n","        super().__init__()\n","        self.factor = factor\n","        self.k = k\n","        self.D = D\n","        self.device = device\n","        self.mlp = nn.Sequential(nn.Linear(in_channel*k,in_channel*(factor-1)))\n","\n","\n","    def forward(self,x):\n","        # x has shape B x N x D\n","        B, N, C = x.shape\n","        nieghbor_num = (2**(self.D-1)) * self.k\n","        batch_tensor = torch.repeat_interleave(torch.arange(B),N).to(self.device)\n","        neighbours = (knn_graph(x.reshape(B*N,-1),k=nieghbor_num,batch=batch_tensor)[0]%N).reshape(B,N,-1)\n","        indexes = neighbours[:,:,torch.outer(torch.pow(2,torch.arange(self.D)),torch.arange(self.k))]\n","        batches = torch.arange(B)[:,None]\n","        prep = x[batches,indexes.reshape(B,-1)].reshape((B,N,self.D,-1))\n","        prep = self.mlp(prep) # has shape B x N x D x (factor-1)*c\n","        new_vertices = torch.max(prep,dim=-2)[0] # has shape B x N x (factor-1)*c\n","        return torch.cat((x,new_vertices),dim=-1).reshape((B,-1,C))\n","\n","class upScaling(nn.Module):\n","    def __init__(self, in_channel, out_channel, factor, device):\n","        super().__init__()\n","        self.factor = factor\n","        self.conv = SRGCN('conv',in_channel,out_channel,device)\n","\n","    def forward(self,x:torch.Tensor):\n","        x = x.repeat_interleave(self.factor,dim=1)\n","        return self.conv(x)\n","\n","\n","class batchNorm(nn.Module):\n","    def __init__(self, in_channels, eps=0.00001):\n","        super(batchNorm,self).__init__()\n","        self.b = nn.BatchNorm1d(in_channels,eps)\n","    def forward(self,x:torch.Tensor):\n","        B, N, D = x.shape\n","        x = x.swapaxes(1,2)\n","        x = self.b(x)\n","        return x.swapaxes(1,2)\n","\n","class DownBlock(nn.Module):\n","    def __init__(self, in_channel, out_channel, device, stride=1):\n","        super().__init__()\n","        self.conv1 = SRGCN('conv',in_channel,out_channel, device, stride=stride)\n","        self.batch1 = batchNorm(out_channel)\n","        self.conv2 = SRGCN('conv',out_channel,out_channel,device)\n","        self.batch2 = batchNorm(out_channel)\n","        self.relu = nn.PReLU()\n","        self.id = None\n","        if stride>1:\n","            self.id =nn.Sequential(SRGCN('conv',in_channel,out_channel,device,stride=stride),batchNorm(out_channel))\n","    def forward(self,x):\n","        identety = x\n","        x = self.conv1(x)\n","        x = self.batch1(x)\n","        x = self.conv2(x)\n","        x = self.batch2(x)\n","        if self.id is not None:\n","            identety = self.id(identety)\n","        return self.relu(x+identety)\n","\n","class UpBlock(nn.Module):\n","    def __init__(self,in_channel, out_channel, device, factor=2, D=4, k=9, last_block=False):\n","        super().__init__()\n","        self.last_block = last_block\n","        self.conv = SRGCN('conv',in_channel,out_channel,device)\n","        self.batch1 = batchNorm(out_channel)\n","\n","        self.up = Upsampling(out_channel,device,factor,k,D)\n","        self.batch2 = batchNorm(out_channel)\n","\n","        self.relu = nn.PReLU()\n","        self.id = None\n","        if factor>1:\n","            self.id = nn.Sequential(upScaling(in_channel,out_channel,factor,device),batchNorm(out_channel))\n","\n","    def forward(self,x):\n","        identity = x\n","        x = self.conv(x)\n","        x = self.batch1(x)\n","        x = self.up(x)\n","        x = self.batch2(x)\n","        if self.id is not None:\n","            identity = self.id(identity)\n","        if (self.last_block):\n","            return x + identity\n","        return self.relu(x+identity)"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1693772095469,"user":{"displayName":"sepehr kazemi","userId":"16765035425808681494"},"user_tz":-210},"id":"8-cVFnra7r7A"},"outputs":[],"source":["class PointCloudCompletion(nn.Module):\n","    def __init__(self,device):\n","        super().__init__()\n","        self.conv1 = SRGCN('conv',3,64,device,k=49)\n","        self.relu1 = nn.PReLU()\n","        self.maxpool = SRGCN('max',64,64,device,k=3,stride=2) # 256 x 64\n","        self.batch1 = batchNorm(64)\n","        self.down1 = DownBlock(64,128,device,stride=2) # 128 x 128\n","        self.down2 = DownBlock(128,256,device,stride=2) # 64 x 256\n","        self.down3 = DownBlock(256,512,device,stride=2) # 32 x 512\n","        self.conv2 = SRGCN('conv',512,512,device)\n","        self.batch2 = batchNorm(512)\n","        self.up1 = UpBlock(512,256,device,2,k=3) # 64 x 256\n","        self.up2 = UpBlock(512,128,device,2,k=5) # 128 x 128\n","        self.up3 = UpBlock(256,64,device,2,k=7) # 256 x 64\n","        self.up4 = UpBlock(64,3,device,2,k=9) # 512 x 3\n","        self.up5 = UpBlock(3,3,device,2,k=11) # 1024 x 3\n","        self.up6 = UpBlock(3,3,device,2,last_block=True,k=11) # 2048 x 3\n","\n","    def forward(self,x):\n","        x = self.conv1(x)\n","        x = self.relu1(x)\n","        x = self.maxpool(x)\n","        x = self.batch1(x)\n","        x = self.down1(x)\n","        down1 = x\n","        x = self.down2(x)\n","        down2 = x\n","        x = self.down3(x)\n","        x = self.conv2(x)\n","        x = self.batch2(x)\n","        x = self.up1(x)\n","        x = self.up2(torch.cat((x,down2),dim=-1))\n","        x = self.up3(torch.cat((x,down1),dim=-1))\n","        x = self.up4(x)\n","        x = self.up5(x)\n","        x = self.up6(x)\n","        return x"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":495,"status":"ok","timestamp":1693771919273,"user":{"displayName":"sepehr kazemi","userId":"16765035425808681494"},"user_tz":-210},"id":"DiTducCG7r7A"},"outputs":[],"source":["class ChafmerDistance(nn.Module):\n","    def __init__(self,device):\n","        super(ChafmerDistance,self).__init__()\n","        self.device = device\n","\n","    def forward(self,P:torch.Tensor,G:torch.Tensor):\n","        B, N, C = P.shape\n","        batches = torch.arange(B)[:,None]\n","        batch_tensor = torch.repeat_interleave(torch.arange(B),N).to(device)\n","\n","        indexes = (knn(G.reshape(B*N,-1),P.reshape(B*N,-1),1,batch_tensor,batch_tensor)[1]%N).reshape(B,N,-1).squeeze()\n","        termP_G = torch.norm(G[batches,indexes] - P,dim=-1).sum(dim=-1) /N\n","\n","        indexes = (knn(P.reshape(B*N,-1),G.reshape(B*N,-1),1,batch_tensor,batch_tensor)[1]%N).reshape(B,N,-1).squeeze()\n","        termG_P = torch.norm(P[batches,indexes] - G,dim=-1).sum(dim=-1) /N\n","\n","        return (termG_P + termP_G).mean()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":407},"executionInfo":{"elapsed":2049565,"status":"error","timestamp":1693774152430,"user":{"displayName":"sepehr kazemi","userId":"16765035425808681494"},"user_tz":-210},"id":"FUhBkcznfhdV","outputId":"a12e4c8c-8104-4064-c8a6-f2dccb04ee39"},"outputs":[],"source":["learning_rate = 0.0001\n","epoch_nums = 1\n","model = PointCloudCompletion(device).to(device)\n","loss_criterion = ChafmerDistance(device).to(device)\n","b1 = 0.5\n","b2 = 0.999\n","optimizer = torch.optim.Adam(params=model.parameters(), lr=learning_rate, betas=(b1,b2))\n","batch_num = len(trainLoader)\n","losses = []\n","for epoch in range(epoch_nums):  # loop over the dataset multiple times\n","\n","    running_loss = 0.0\n","    tqdm_bar = tqdm(trainLoader, desc=f'Training Epoch {epoch} ', total=int(len(trainLoader)))\n","    model.train()\n","    for i, data in enumerate(tqdm_bar):\n","        ## FILL HERE\n","        ## You should train the model and also print the running loss for each batch\n","        partial_pc, complete_pc  = data\n","        partial_pc = partial_pc.to(device)\n","        complete_pc = complete_pc.to(device)\n","        predicted_pc = model(partial_pc)\n","        optimizer.zero_grad()\n","        loss = loss_criterion(predicted_pc, complete_pc)\n","        loss.backward()\n","        optimizer.step()\n","        running_loss += loss.item()\n","\n","    running_loss /= batch_num\n","    losses.append(running_loss)\n","    print('epoch : ',epoch,', loss : ',running_loss)\n","print('Finished Training')\n"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.6"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":0}
